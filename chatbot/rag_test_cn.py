#!/usr/bin/env python3
"""
ç®€å†RAG QAç³»ç»Ÿ
åŸºäºXLSXæ–‡ä»¶çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œä½¿ç”¨DeepSeek-V3.1æ¨¡å‹
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
import os
import re
from openai import OpenAI

class ResumeRAGSystem:
    def __init__(self, xlsx_path: str = None):
        """
        åˆå§‹åŒ–ç®€å†RAGç³»ç»Ÿ
        
        Args:
            xlsx_path: XLSXæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        """
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='ms-74b8eedd-5f76-419a-a513-f421399093da'
        )
        
        # åŠ è½½æ•°æ®
        self.data = self._load_data(xlsx_path)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(self.data)} æ¡è®°å½•")
        
    def _load_data(self, xlsx_path: str = None) -> pd.DataFrame:
        """åŠ è½½XLSXæ•°æ®æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®"""
        if xlsx_path and os.path.exists(xlsx_path):
            try:
                df = pd.read_excel(xlsx_path)
                print(f"ğŸ“ ä»æ–‡ä»¶åŠ è½½æ•°æ®: {xlsx_path}")
                return df
            except Exception as e:
                print(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                print("ğŸ”„ ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
        else:
            print("ğŸ“ ä½¿ç”¨å†…ç½®ç¤ºä¾‹æ•°æ®")
            
        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        return pd.DataFrame([
            {
                "type": "Work",
                "company_organization": "Baidu Inc.",
                "position_title": "AI/ML Engineer",
                "context": "Enhanced the Outline Generation module's performance through a multi-stage data pipeline that included model Supervised fine-tuning (LoRA), log data cleansing and annotation, resulting in an 80% win rate in GSB evaluations. Technologies: LoRA, Data Pipeline, Model Fine-tuning"
            },
            {
                "type": "Work",
                "company_organization": "Baidu Inc.",
                "position_title": "AI/ML Engineer",
                "context": "Automated 40% of data annotation tasks by leveraging role-playing prompt engineering on the Deepseek-v3, also optimized 3 evaluation rules salvaging 20+% of data for valuable use. Technologies: Deepseek-v3, Prompt Engineering"
            },
            {
                "type": "Work",
                "company_organization": "Baidu Inc.",
                "position_title": "AI/ML Engineer",
                "context": "Accelerated the template update speed of Baidu Wenku's AI PPT Generator by leveraging LLM Fine-Tuning and post processing strategies, achieving 90% stability and enabling the deployment of 300+ templates. Technologies: LLM Fine-Tuning, Post Processing"
            },
            {
                "type": "Work",
                "company_organization": "Baidu Inc.",
                "position_title": "AI/ML Engineer",
                "context": "Evaluated the latest LLM models(Deepseek) and applied it to text to tabular data task, achieving 95% accuracy. Technologies: Deepseek, LLM Evaluation"
            },
            {
                "type": "Work",
                "company_organization": "Apple Inc.",
                "position_title": "Data Scientist",
                "context": "Leveraged Word Embedding and MiniBatch K-Means to analyze real-time chat data from a newly launched Apple TikTok live-stream, identifying top 10 categories that informed script optimizations and resulted in a 7% reduction in return rate. Technologies: Word Embedding, MiniBatch K-Means, Real-time Data Analysis"
            },
            {
                "type": "Work",
                "company_organization": "Apple Inc.",
                "position_title": "Data Scientist",
                "context": "Boosted GenZ viewership by 21.29% and retention by 13.9% on TikTok outdoor live-streams by leveraging A/B testing to optimize content. Technologies: A/B Testing, Content Optimization"
            },
            {
                "type": "Work",
                "company_organization": "Apple Inc.",
                "position_title": "Data Scientist",
                "context": "Informed live content strategy by applying Difference in Difference(DID) analysis to Apple's continuous interconnection scenarios, which resulted in a 3% boost in click-through rates and an 8.9% increase in interaction rates. Technologies: Difference in Difference Analysis, Statistical Analysis"
            },
            {
                "type": "Work",
                "company_organization": "Michelin(China) Investment Co. Ltd.",
                "position_title": "Information Technology Intern",
                "context": "Automated a reseller sentiment analysis system with 75% accuracy using pre-trained Chinese Word Embedding and BiLSTM on e-commerce comments, leading to a 3.2% increase in sales. Technologies: Chinese Word Embedding, BiLSTM, Sentiment Analysis"
            },
            {
                "type": "Work",
                "company_organization": "Michelin(China) Investment Co. Ltd.",
                "position_title": "Information Technology Intern",
                "context": "Extracted 3000+ tire specifications from websites like Tesla and BYD by leveraging a Python Scrapy web crawler, providing crucial market data to inform product strategy for a new electric vehicle tire series. Technologies: Python, Scrapy, Web Crawling"
            },
            {
                "type": "Work",
                "company_organization": "Michelin(China) Investment Co. Ltd.",
                "position_title": "Information Technology Intern",
                "context": "Developed a data pipeline and visualization module for SharePoint internal software by integrating and processing unstructured data sources, which drove strategic SKU selection for a new tire launch in the Asia-Pacific region. Technologies: Data Pipeline, SharePoint, Data Visualization"
            },
            {
                "type": "Project",
                "company_organization": "Machine Learning Course",
                "position_title": "A Deep Reinforcement Learning Based Stock Automated Trading System",
                "context": "Developed a Deep Deterministic Policy Gradient-based automated trading agent, leveraging advanced data preprocessing to improve annual returns by 10% in backtesting scenarios. Technologies: Deep Reinforcement Learning, DDPG, Data Preprocessing"
            },
            {
                "type": "Project",
                "company_organization": "Undergraduate Research",
                "position_title": "Facial Emotion Recognition System",
                "context": "Developed a CNN-based facial emotion classifier with 80% accuracy on the FER-2013 dataset. Integrated the classifier into an interactive PyQt5 system to analyze emotional data and visualize insights. Award: Excellent Award. Technologies: CNN, PyQt5, FER-2013 Dataset, Data Visualization, Emotion Analysis"
            }
        ])
    
    def _simple_similarity_search(self, query: str, k: int = 5) -> List[Dict]:
        """ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦æœç´¢"""
        query_lower = query.lower()
        query_words = set(re.findall(r'\w+', query_lower))
        
        results = []
        for idx, row in self.data.iterrows():
            # ç»„åˆæ‰€æœ‰æ–‡æœ¬å†…å®¹
            content = f"{row.get('type', '')} {row.get('company_organization', '')} {row.get('position_title', '')} {row.get('context', '')}"
            content_lower = content.lower()
            content_words = set(re.findall(r'\w+', content_lower))
            
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
            # 1. å…³é”®è¯åŒ¹é…
            common_words = query_words.intersection(content_words)
            keyword_score = len(common_words) / max(len(query_words), 1)
            
            # 2. å®Œæ•´è¯åŒ¹é…åŠ æƒ
            exact_matches = sum(1 for word in query_words if word in content_lower)
            exact_score = exact_matches / max(len(query_words), 1)
            
            # 3. é•¿åº¦åŒ¹é…å¥–åŠ±
            length_bonus = min(len(content_words) / 50, 1) * 0.1
            
            # ç»¼åˆåˆ†æ•°
            total_score = keyword_score * 0.6 + exact_score * 0.3 + length_bonus
            
            if total_score > 0:
                results.append({
                    'score': total_score,
                    'data': row,
                    'index': idx
                })
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›å‰kä¸ª
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:k]
    
    def _create_prompt(self, query: str, relevant_data: List[Dict]) -> str:
        """åˆ›å»ºæç¤ºè¯"""
        if not relevant_data:
            return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†åˆ†æåŠ©æ‰‹ã€‚

ç”¨æˆ·é—®é¢˜: {query}

å¾ˆæŠ±æ­‰ï¼Œæˆ‘åœ¨ç®€å†ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚è¯·å°è¯•è¯¢é—®å…¶ä»–å†…å®¹ï¼Œæˆ–è€…æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸ç®€å†ä¿¡æ¯ç›¸å…³ã€‚

è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚
"""
        
        context_parts = []
        for item in relevant_data:
            row = item['data']
            context_part = f"""
ç±»å‹: {row.get('type', 'æœªçŸ¥')}
å…¬å¸/ç»„ç»‡: {row.get('company_organization', 'æœªçŸ¥')}
èŒä½/é¡¹ç›®: {row.get('position_title', 'æœªçŸ¥')}
è¯¦ç»†ä¿¡æ¯: {row.get('context', 'æš‚æ— è¯¦ç»†ä¿¡æ¯')}
---"""
            context_parts.append(context_part)
        
        context = "\n".join(context_parts)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†åˆ†æåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ç®€å†ä¿¡æ¯å‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç®€å†ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {query}

è¯·æ ¹æ®æä¾›çš„ç®€å†ä¿¡æ¯å‡†ç¡®å›ç­”é—®é¢˜ã€‚å›ç­”è¦æ±‚ï¼š
1. åŸºäºç®€å†å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. çªå‡ºç›¸å…³çš„æŠ€èƒ½ã€æˆå°±å’Œæ•°æ®
4. å›ç­”è¦ç»“æ„åŒ–ã€æ¡ç†æ¸…æ™°
5. ç”¨ä¸­æ–‡å›ç­”

å›ç­”:
"""
        return prompt
    
    def query(self, question: str, stream: bool = True) -> str:
        """
        æŸ¥è¯¢ç®€å†ä¿¡æ¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            å›ç­”å­—ç¬¦ä¸²
        """
        print(f"\nğŸ” æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯...")
        
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        relevant_data = self._simple_similarity_search(question, k=5)
        
        if relevant_data:
            print(f"ğŸ“Š æ‰¾åˆ° {len(relevant_data)} æ¡ç›¸å…³ä¿¡æ¯")
            for i, item in enumerate(relevant_data[:3], 1):
                score = item['score']
                company = item['data'].get('company_organization', 'æœªçŸ¥')
                position = item['data'].get('position_title', 'æœªçŸ¥')
                print(f"   {i}. {company} - {position} (ç›¸å…³åº¦: {score:.2f})")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
        
        # 2. æ„å»ºæç¤ºè¯
        prompt = self._create_prompt(question, relevant_data)
        
        # 3. è°ƒç”¨æ¨¡å‹
        try:
            print(f"\nğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
            response = self.client.chat.completions.create(
                model='deepseek-ai/DeepSeek-V3.1',
                messages=[
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                stream=stream,
                temperature=0.7,
                max_tokens=2000
            )
            
            if stream:
                return self._handle_stream_response(response)
            else:
                return response.choices[0].message.content
                
        except Exception as e:
            error_msg = f"âŒ æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(error_msg)
            return error_msg
    
    def _handle_stream_response(self, response) -> str:
        """å¤„ç†æµå¼å“åº”"""
        full_answer = ""
        done_reasoning = False
        
        try:
            print("\n" + "="*60)
            for chunk in response:
                delta = chunk.choices[0].delta
                
                # å¤„ç†æ¨ç†å†…å®¹
                reasoning_chunk = getattr(delta, 'reasoning_content', None) or ""
                if reasoning_chunk:
                    print(reasoning_chunk, end='', flush=True)
                
                # å¤„ç†å›ç­”å†…å®¹
                answer_chunk = getattr(delta, 'content', None) or ""
                if answer_chunk:
                    if not done_reasoning and reasoning_chunk == "":
                        print('\n\nğŸ’¡ å›ç­”:\n')
                        done_reasoning = True
                    print(answer_chunk, end='', flush=True)
                    full_answer += answer_chunk
            
            print("\n" + "="*60)
            return full_answer
            
        except Exception as e:
            error_msg = f"\nâŒ å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}"
            print(error_msg)
            return error_msg
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ç®€å†æ‘˜è¦ç»Ÿè®¡"""
        work_data = self.data[self.data['type'] == 'Work']
        project_data = self.data[self.data['type'] == 'Project']
        
        summary = {
            "æ€»è®°å½•æ•°": len(self.data),
            "å·¥ä½œç»å†": len(work_data),
            "é¡¹ç›®ç»å†": len(project_data),
            "æ¶‰åŠå…¬å¸": list(self.data['company_organization'].unique()),
            "æŠ€èƒ½å…³é”®è¯": self._extract_skills()
        }
        return summary
    
    def _extract_skills(self) -> List[str]:
        """æå–æŠ€èƒ½å…³é”®è¯"""
        skills = set()
        
        # ä»contextä¸­æå–Technologiesåé¢çš„å†…å®¹
        for _, row in self.data.iterrows():
            context = row.get('context', '')
            
            # æŸ¥æ‰¾Technologies: åé¢çš„å†…å®¹
            tech_match = re.search(r'Technologies:\s*([^.]+)', context)
            if tech_match:
                tech_text = tech_match.group(1)
                # æŒ‰é€—å·åˆ†å‰²å¹¶æ¸…ç†
                tech_items = [item.strip() for item in tech_text.split(',')]
                skills.update(tech_items)
        
        return sorted(list(skills))[:10]  # è¿”å›å‰10ä¸ªæŠ€èƒ½
    
    def search_by_company(self, company: str) -> pd.DataFrame:
        """æŒ‰å…¬å¸æœç´¢"""
        mask = self.data['company_organization'].str.contains(company, case=False, na=False)
        return self.data[mask]
    
    def search_by_skill(self, skill: str) -> pd.DataFrame:
        """æŒ‰æŠ€èƒ½æœç´¢"""
        mask = self.data['context'].str.contains(skill, case=False, na=False)
        return self.data[mask]

def main():
    """ä¸»å‡½æ•° - äº¤äº’å¼é—®ç­”"""
    print("ğŸš€ ç®€å†RAG QAç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("=" * 60)
    
    # è·å–XLSXæ–‡ä»¶è·¯å¾„
    xlsx_path = input("ğŸ“ è¯·è¾“å…¥XLSXæ–‡ä»¶è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨ç¤ºä¾‹æ•°æ®): ").strip()
    if not xlsx_path:
        xlsx_path = None
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        rag_system = ResumeRAGSystem(xlsx_path)
        
        # æ˜¾ç¤ºæ‘˜è¦
        summary = rag_system.get_summary()
        print(f"\nğŸ“Š ç®€å†æ‘˜è¦:")
        print(f"   æ€»è®°å½•æ•°: {summary['æ€»è®°å½•æ•°']}")
        print(f"   å·¥ä½œç»å†: {summary['å·¥ä½œç»å†']}")
        print(f"   é¡¹ç›®ç»å†: {summary['é¡¹ç›®ç»å†']}")
        print(f"   æ¶‰åŠå…¬å¸: {', '.join(summary['æ¶‰åŠå…¬å¸'][:5])}")
        print(f"   ä¸»è¦æŠ€èƒ½: {', '.join(summary['æŠ€èƒ½å…³é”®è¯'][:8])}")
        
        print(f"\nğŸ’¡ ç³»ç»Ÿå·²å°±ç»ªï¼è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
        print("   è¾“å…¥ 'quit' æˆ– 'q' é€€å‡º")
        print("   è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
        print("=" * 60)
        
        # äº¤äº’å¾ªç¯
        while True:
            try:
                question = input("\nğŸ” è¯·è¾“å…¥é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                    break
                
                if question.lower() in ['help', 'å¸®åŠ©', 'h']:
                    show_help()
                    continue
                
                if not question:
                    print("â— è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜")
                    continue
                
                # å¤„ç†æŸ¥è¯¢
                answer = rag_system.query(question)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print(f"\nğŸ“– å¸®åŠ©ä¿¡æ¯:")
    print(f"   â€¢ è¯¢é—®å·¥ä½œç»å†: 'åœ¨ç™¾åº¦åšäº†ä»€ä¹ˆå·¥ä½œï¼Ÿ'")
    print(f"   â€¢ è¯¢é—®é¡¹ç›®ç»éªŒ: 'æœ‰å“ªäº›æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Ÿ'")
    print(f"   â€¢ è¯¢é—®æŠ€èƒ½: 'æŒæ¡å“ªäº›æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Ÿ'")
    print(f"   â€¢ è¯¢é—®æˆæœ: 'Appleå®ä¹ çš„ä¸»è¦æˆæœæ˜¯ä»€ä¹ˆï¼Ÿ'")
    print(f"   â€¢ æ•°æ®åˆ†æ: 'æœ‰ä»€ä¹ˆæ•°æ®åˆ†æç›¸å…³çš„ç»éªŒï¼Ÿ'")
    print(f"   â€¢ å…¬å¸å¯¹æ¯”: 'åœ¨ä¸åŒå…¬å¸çš„å·¥ä½œæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ'")

def batch_test():
    """æ‰¹é‡æµ‹è¯•åŠŸèƒ½"""
    print("ğŸ§ª æ‰¹é‡æµ‹è¯•æ¨¡å¼")
    
    rag_system = ResumeRAGSystem()
    
    test_questions = [
        "åœ¨ç™¾åº¦å®ä¹ æœŸé—´åšäº†ä»€ä¹ˆå·¥ä½œï¼Ÿ",
        "æœ‰å“ªäº›æœºå™¨å­¦ä¹ é¡¹ç›®ç»éªŒï¼Ÿ",
        "ä½¿ç”¨è¿‡å“ªäº›æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Ÿ",
        "åœ¨Appleçš„å·¥ä½œæˆæœæ˜¯ä»€ä¹ˆï¼Ÿ",
        "æœ‰ä»€ä¹ˆæ•°æ®åˆ†æç»éªŒï¼Ÿ",
        "æŒæ¡å“ªäº›ç¼–ç¨‹æŠ€èƒ½ï¼Ÿ"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•é—®é¢˜ {i}: {question}")
        print(f"{'='*60}")
        
        try:
            answer = rag_system.query(question, stream=False)
            print(f"\nå›ç­”: {answer}")
        except Exception as e:
            print(f"é”™è¯¯: {str(e)}")
        
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜...")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            batch_test()
        elif sys.argv[1] == "help":
            show_help()
        else:
            print("ç”¨æ³•:")
            print("  python script.py        # äº¤äº’æ¨¡å¼")
            print("  python script.py test   # æ‰¹é‡æµ‹è¯•")
            print("  python script.py help   # æ˜¾ç¤ºå¸®åŠ©")
    else:
        main()

# ä¾èµ–å®‰è£…å‘½ä»¤:
# pip install pandas numpy openai openpyxl