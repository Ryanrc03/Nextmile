"""
Chatbot Module - äººæ€§åŒ–å¯¹è¯æ¥å£
æ•´åˆ RAG ç»„ä»¶ï¼Œæä¾›å¸¦è®°å¿†çš„å¯¹è¯åŠŸèƒ½
èŒè´£ï¼šè°ƒç”¨ retrieval å’Œ generation æ¨¡å—ï¼Œç®¡ç†å¯¹è¯è®°å¿†å’Œäº¤äº’
"""

from langchain.memory import ConversationBufferMemory
from typing import List, Dict, Any, Optional
import logging

# å¯¼å…¥ retrieval å’Œ generation æ¨¡å—
from retreival import load_chroma_db, retrieve_similar_documents
from generation import ResumeRAGGenerator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ResumeChatbot:
    """
    å¸¦è®°å¿†çš„ç®€å†é—®ç­”èŠå¤©æœºå™¨äºº
    æ•´åˆæ£€ç´¢å’Œç”ŸæˆåŠŸèƒ½ï¼Œæä¾›äººæ€§åŒ–çš„å¯¹è¯ä½“éªŒ
    """
    
    def __init__(self, persist_directory="docs/chroma/", config: Optional[Dict] = None):
        """
        Initialize the chatbot
        
        Args:
            persist_directory (str): ChromaDB å­˜å‚¨ç›®å½•
            config (dict): å¯é€‰é…ç½®
        """
        # åˆå§‹åŒ–æ£€ç´¢æ¨¡å—ï¼ˆç›´æ¥åŠ è½½ ChromaDBï¼‰
        self.vectordb = load_chroma_db(persist_directory)
        
        # åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—
        self.generator = ResumeRAGGenerator(persist_directory, config)
        
        # åˆå§‹åŒ–å¯¹è¯è®°å¿†
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # å¯¹è¯å†å²ï¼ˆç”¨äºç®€å•å±•ç¤ºï¼‰
        self.conversation_history = []
        
        # æ¬¢è¿æ¶ˆæ¯
        self.welcome_message = "Hello! How can I assist you today? Feel free to ask me anything about my background, experience, or skills!"
        
        logger.info("Chatbot initialized successfully")
    
    def _build_prompt_with_history(self, question: str, retrieved_docs: List[Dict[str, Any]]) -> str:
        """
        æ„å»ºåŒ…å«å¯¹è¯å†å²çš„ prompt
        
        Args:
            question (str): ç”¨æˆ·é—®é¢˜
            retrieved_docs (list): æ£€ç´¢åˆ°çš„æ–‡æ¡£
            
        Returns:
            å®Œæ•´çš„ prompt
        """
        # è·å–å¯¹è¯å†å²
        chat_history = self.memory.load_memory_variables({}).get("chat_history", [])
        
        # æ„å»ºå†å²å¯¹è¯æ–‡æœ¬
        history_text = ""
        if chat_history:
            history_text = "\nPrevious Conversation:\n"
            for msg in chat_history[-4:]:  # åªä¿ç•™æœ€è¿‘4è½®å¯¹è¯
                role = "User" if msg.type == "human" else "Assistant"
                history_text += f"{role}: {msg.content}\n"
            history_text += "\n"
        
        # æ„å»ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        if not retrieved_docs:
            context = "No specific background information found for this query."
        else:
            context_parts = []
            for doc in retrieved_docs[:3]:  # åªä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
                content = doc['content']
                metadata = doc.get('metadata', {})
                context_part = f"""
Source: {metadata.get('source', 'Unknown')} (Page {metadata.get('page', 'N/A')})
Content: {content}
---"""
                context_parts.append(context_part)
            context = "\n".join(context_parts)
        
        # æ„å»ºå®Œæ•´ prompt
        prompt = f"""
            You are my digital avatar, speaking as if you were me personally. Answer user questions in a casual, conversational way as if we're having a friendly chat.

{history_text}
My Background (Retrieved Context):
{context}

Current Question: {question}

    Instructions:
    1. Answer as "me" - use first person (I did this, I worked on, I have experience with)
    2. Keep responses conversational and concise (2-4 sentences typically)
    3. If the question relates to previous conversation, acknowledge and build on it naturally
    4. Show technical competence without being overly detailed
    5. Be friendly and approachable, like chatting with a colleague
    6. If you don't have enough info, say so naturally ("I don't think I've worked on that" or "That's not in my experience")
    7. Answer in English
    8. Don't be overly formal - sound human and relatable
    9. If appropriate, end with a friendly follow-up like "Feel free to ask more!" or "Anything else you'd like to know?"

    Answer naturally as me:
    """
        return prompt
    
    def chat(self, user_input: str, top_k: int = 5, stream: bool = False) -> Dict[str, Any]:
        """
        ä¸ç”¨æˆ·å¯¹è¯ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        è°ƒç”¨ retrieval æ¨¡å—æ£€ç´¢ï¼Œè°ƒç”¨ generation æ¨¡å—ç”Ÿæˆå›ç­”
        
        Args:
            user_input (str): ç”¨æˆ·è¾“å…¥
            top_k (int): æ£€ç´¢æ–‡æ¡£æ•°é‡
            stream (bool): æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            
        Returns:
            åŒ…å«å›ç­”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            # 1. ä½¿ç”¨ retrieval æ¨¡å—æ£€ç´¢ç›¸å…³æ–‡æ¡£
            retrieved_results = retrieve_similar_documents(user_input, self.vectordb, top_k)
            
            # å°†æ£€ç´¢ç»“æœè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            retrieved_docs = []
            for i, doc in enumerate(retrieved_results):
                retrieved_docs.append({
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'rank': i + 1
                })
            
            # 2. æ„å»ºå¸¦å†å²çš„ prompt
            prompt = self._build_prompt_with_history(user_input, retrieved_docs)
            
            # 3. ä½¿ç”¨ generation æ¨¡å—ç”Ÿæˆå›ç­”
            answer = self.generator.generate_response(prompt, stream)
            
            # 4. ä¿å­˜åˆ°è®°å¿†ä¸­
            self.memory.save_context(
                {"input": user_input},
                {"answer": answer}
            )
            
            # 5. ä¿å­˜åˆ°å¯¹è¯å†å²
            self.conversation_history.append({
                "role": "user",
                "content": user_input
            })
            self.conversation_history.append({
                "role": "assistant",
                "content": answer
            })
            
            result = {
                "answer": answer,
                "retrieved_docs": retrieved_docs,
                "retrieved_count": len(retrieved_docs),
                "success": True
            }
            
            logger.info(f"Chat completed with {len(retrieved_docs)} retrieved documents")
            return result
            
        except Exception as e:
            error_msg = f"Error during chat: {str(e)}"
            logger.error(error_msg)
            
            return {
                "answer": f"Sorry, I encountered an error: {str(e)}",
                "retrieved_docs": [],
                "retrieved_count": 0,
                "success": False,
                "error": str(e)
            }
    
    def get_welcome_message(self) -> str:
        """è·å–æ¬¢è¿æ¶ˆæ¯"""
        return self.welcome_message
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.memory.clear()
        self.conversation_history = []
        logger.info("Conversation history cleared")
    
    def get_memory_summary(self) -> str:
        """è·å–è®°å¿†æ‘˜è¦"""
        chat_history = self.memory.load_memory_variables({}).get("chat_history", [])
        if not chat_history:
            return "No conversation history yet."
        
        summary = f"Conversation has {len(chat_history)} messages:\n"
        for i, msg in enumerate(chat_history[-6:], 1):  # æ˜¾ç¤ºæœ€è¿‘6æ¡
            role = "User" if msg.type == "human" else "Assistant"
            content_preview = msg.content[:80] + "..." if len(msg.content) > 80 else msg.content
            summary += f"{i}. {role}: {content_preview}\n"
        
        return summary
    
    def run_interactive(self):
        """
        è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯ï¼ˆå‘½ä»¤è¡Œç•Œé¢ï¼‰
        """
        print("="*60)
        print(self.welcome_message)
        print("="*60)
        print("Type 'exit' or 'quit' to end the conversation")
        print("Type 'history' to see conversation history")
        print("Type 'clear' to clear conversation history")
        print("="*60)
        
        while True:
            try:
                user_input = input("\n You: ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['exit', 'quit', 'bye']:
                    print("\nAssistant: Thanks for chatting! Have a great day! ğŸ‘‹")
                    break
                
                if user_input.lower() == 'history':
                    print("\n" + self.get_memory_summary())
                    continue
                
                if user_input.lower() == 'clear':
                    self.clear_history()
                    print("\nAssistant: Conversation history cleared! Let's start fresh.")
                    continue
                
                # æ­£å¸¸å¯¹è¯
                print("\nAssistant: ", end="", flush=True)
                result = self.chat(user_input, top_k=3, stream=True)
                
                if not result["success"]:
                    print(f"\n[Error: {result.get('error', 'Unknown error')}]")
                
            except KeyboardInterrupt:
                print("\n\nAssistant: Goodbye! ğŸ‘‹")
                break
            except Exception as e:
                print(f"\n[Unexpected error: {str(e)}]")
                logger.error(f"Interactive chat error: {str(e)}")


# Example usage and testing
if __name__ == "__main__":
    # åˆå§‹åŒ– chatbot
    chatbot = ResumeChatbot(persist_directory="docs/chroma/")
    
    # æ–¹å¼ 1: äº¤äº’å¼å‘½ä»¤è¡ŒèŠå¤©
    print("\n=== Starting Interactive Chat ===\n")
    chatbot.run_interactive()
    
    # æ–¹å¼ 2: ç¨‹åºåŒ–æµ‹è¯•ï¼ˆæ³¨é‡Šæ‰äº¤äº’å¼åå¯è¿è¡Œï¼‰
    """
    print("\n=== Testing Chatbot Programmatically ===\n")
    
    # æµ‹è¯•å¯¹è¯
    test_conversations = [
        "What are your main skills?",
        "Tell me more about your machine learning experience",
        "Have you worked with deep learning?"
    ]
    
    print(f"Chatbot: {chatbot.get_welcome_message()}\n")
    
    for question in test_conversations:
        print(f"User: {question}")
        result = chatbot.chat(question, top_k=3, stream=False)
        print(f"Chatbot: {result['answer']}")
        print(f"[Retrieved {result['retrieved_count']} documents]\n")
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    print("\n=== Conversation History ===")
    print(chatbot.get_memory_summary())
    """
